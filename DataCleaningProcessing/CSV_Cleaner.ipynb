{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This transforms the raw csv files (just single column with all the wanted column values in a quasi-uniform pattern to a csv file with the wanted columns. We need to set up checkers to make sure that the rows are correct because the tabula application isnt perfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2011 = pd.read_csv(\"raw_CSV/2011.csv\", sep=',', header=None)\n",
    "r2012 = pd.read_csv(\"raw_CSV/2012.csv\", sep=',', header=None)\n",
    "r2013 = pd.read_csv(\"raw_CSV/2013.csv\", sep=',', header=None)\n",
    "r2014 = pd.read_csv(\"raw_CSV/2014.csv\", sep=',', header=None)\n",
    "r2015 = pd.read_csv(\"raw_CSV/2015.csv\", sep=',', header=None)\n",
    "r2016 = pd.read_csv(\"raw_CSV/2016.csv\", sep=',', header=None)\n",
    "r2017 = pd.read_csv(\"raw_CSV/2017.csv\", sep=',', header=None)\n",
    "r2018 = pd.read_csv(\"raw_CSV/2018.csv\", sep=',', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we know the pattern is this event -> location -> \"date reported\" -> Incident/Case# -> Date Occured -> Time Occurred -> Summary -> Dispostion.\n",
    "# Therefore we can write an algorithm that adds None to all the if the iterator does not match)\n",
    "def cleaner(raw):\n",
    "    isIncorrectSyntax = True\n",
    "    combine = raw.dropna()\n",
    "    try:\n",
    "        raw[0][combine.index] = combine[0] + \" \" + combine[1]\n",
    "        raw.dropna(subset=[0], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    faultyData = np.array(raw[0])\n",
    "    while isIncorrectSyntax:\n",
    "        for i in range(len(faultyData)):\n",
    "            if i % 8 == 0:\n",
    "                if bool(re.search(\"Date Reported\", faultyData[i])) or bool(re.search(\"Incident/Case#\", faultyData[i])) \\\n",
    "                or bool(re.search(\"Incident/Case#\", faultyData[i])) or bool(re.search(\"Date Occurred\", faultyData[i])) \\\n",
    "                or bool(re.search(\"Time Occurred\", faultyData[i])) or bool(re.search(\"Summary:\", faultyData[i])) \\\n",
    "                or bool(re.search(\"Disposition:\", faultyData[i])):\n",
    "                    faultyData = np.insert(faultyData, i, \"Unknown Event\")\n",
    "            if i % 8 == 1:\n",
    "                if bool(re.search(\"Date Reported\", faultyData[i])) or bool(re.search(\"Incident/Case#\", faultyData[i])) \\\n",
    "                or bool(re.search(\"Incident/Case#\", faultyData[i])) or bool(re.search(\"Date Occurred\", faultyData[i])) \\\n",
    "                or bool(re.search(\"Time Occurred\", faultyData[i])) or bool(re.search(\"Summary:\", faultyData[i])) \\\n",
    "                or bool(re.search(\"Disposition:\", faultyData[i])):\n",
    "                    faultyData = np.insert(faultyData, i, \"Unknown Location\")\n",
    "            if i % 8 == 2:\n",
    "                if not bool(re.search(\"Date Reported\", faultyData[i])):\n",
    "                    print(faultyData[i])\n",
    "                    faultyData = np.insert(faultyData, i, \"Date Reported\")\n",
    "                    break\n",
    "            if i % 8 == 3:\n",
    "                if not bool(re.search(\"Incident/Case#\", faultyData[i])):\n",
    "                    print(faultyData[i])\n",
    "                    faultyData = np.insert(faultyData, i, \"Incident/Case#\")\n",
    "                    break\n",
    "            if i % 8 == 4:\n",
    "                if not bool(re.search(\"Date Occurred\", faultyData[i])):\n",
    "                    print(faultyData[i])\n",
    "                    faultyData = np.insert(faultyData, i, \"Date Occurred\")\n",
    "                    break\n",
    "            if i % 8 == 5:\n",
    "                if not bool(re.search(\"Time Occurred\", faultyData[i])):\n",
    "                    print(faultyData[i])\n",
    "                    faultyData = np.insert(faultyData, i, \"Time Occurred\")\n",
    "                    break\n",
    "            if i % 8 == 6:\n",
    "                if not bool(re.search(\"Summary:\", faultyData[i])):\n",
    "                    print(faultyData[i])\n",
    "                    faultyData = np.insert(faultyData, i, \"Summary:\")\n",
    "                    break\n",
    "                else:\n",
    "                    # This is pretty shitty way to check, but better than nothing\n",
    "                    # another potential checker is [^DELIS] from the first letters of the column headers\n",
    "                    if bool(re.match(r\"^[\\$a-z0-9]\", faultyData[i + 1])):\n",
    "                        print(faultyData[i + 1])\n",
    "                        faultyData[i] = faultyData[i] + \" \" + faultyData[i + 1]\n",
    "                        faultyData = np.delete(faultyData, i + 1)\n",
    "                        break\n",
    "            if i % 8 == 7:\n",
    "                if not bool(re.search(\"Disposition\", faultyData[i])):\n",
    "                    print(faultyData[i])\n",
    "                    faultyData = np.insert(faultyData, i, \"Disposition:\")\n",
    "                    break\n",
    "        else:\n",
    "            isIncorrectSyntax = False\n",
    "    clean = pd.DataFrame(np.array(faultyData).reshape(len(faultyData) // 8, 8))\n",
    "    nameChange = {0: \"Event\", 1: \"Location\", 2:\"Date Reported\", 3: \"Incident/Case#\", 4: \"Date Occurred\", 5:\"Time Occurred\",\n",
    "             6: \"Summary:\", 7: \"Disposition:\"}\n",
    "    clean.rename(columns=nameChange, inplace=True)\n",
    "    clean[\"Date Reported\"] = clean[\"Date Reported\"].map(lambda x: x.replace(\"Date Reported\", \"\").replace('\"', \"\").strip())\n",
    "    clean[\"Date Occurred\"] = clean[\"Date Occurred\"].map(lambda x: x.replace(\"Date Occurred\", \"\").replace('\"', \"\").strip())  \n",
    "    clean[\"Incident/Case#\"] = clean[\"Incident/Case#\"].map(lambda x: x.replace(\"Incident/Case#\", \"\").replace('\"', \"\").strip())\n",
    "    clean[\"Time Occurred\"] = clean[\"Time Occurred\"].map(lambda x: x.replace(\"Time Occurred\", \"\").replace('\"', \"\").strip())\n",
    "    clean[\"Summary:\"] = clean[\"Summary:\"].map(lambda x: x.replace(\"Summary:\", \"\").replace('\"', \"\").strip())\n",
    "    clean[\"Disposition:\"] = clean[\"Disposition:\"].map(lambda x: x.replace(\"Disposition:\", \"\").replace(\"Disposition\", \"\").replace('\"', \"\").strip())\n",
    "    return clean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c2011 = cleaner(r2011)\n",
    "#c2012 = cleaner(r2012)\n",
    "#c2013 = cleaner(r2013)\n",
    "#c2014 = cleaner(r2014)\n",
    "#c2015 = cleaner(r2015)\n",
    "#c2016 = cleaner(r2016)\n",
    "#c2017 = cleaner(r2017)\n",
    "#c2017 = cleaner(r2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I deleted and combined extraneous row here, and checked that tabula got all the cases.  \n",
    "The following code helped identify where errors were as errors were in locations where case# or dispositions are empty.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c2011[c2011.isnull()[\"Incident/Case#\"]]\n",
    "#c2012[c2012.isnull()[\"Incident/Case#\"]]\n",
    "#c2013[c2013.isnull()[\"Incident/Case#\"]]\n",
    "#c2014[c2014.isnull()[\"Incident/Case#\"]]\n",
    "#c2015[c2015.isnull()[\"Incident/Case#\"]]\n",
    "#c2016[c2016.isnull()[\"Incident/Case#\"]]\n",
    "#c2017[c2017.isnull()[\"Incident/Case#\"]]\n",
    "#c2018[c2018.isnull()[\"Incident/Case#\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c2011[c2011.isnull()[\"Disposition:\"]]\n",
    "#c2012[c2012.isnull()[\"Disposition:\"]]\n",
    "#c2013[c2013.isnull()[\"Disposition:\"]]\n",
    "#c2014[c2014.isnull()[\"Disposition:\"]]\n",
    "#c2015[c2015.isnull()[\"Disposition:\"]]\n",
    "#c2016[c2016.isnull()[\"Disposition:\"]]\n",
    "#c2017[c2017.isnull()[\"Disposition:\"]]\n",
    "#c2018[c2018.isnull()[\"Disposition:\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main reason i didn't combine them is to make processing easier. Finding missing values on the PDF that tabula didn't pick up takes up to 10 seconds for it to search. \n",
    "\n",
    "I used excel since it was easier to input\n",
    "A few disadavantages of using excel:\n",
    "1. If you mess up in an earlier stage or want to revert back to an earlier stage, you're out of luck\n",
    "2. Its not reproducable; you're gonna have to rely on me on making sure everything is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c2011.to_csv(\"c2011.csv\", index=False)\n",
    "#c2012.to_csv(\"c2012.csv\", index=False)\n",
    "#c2013.to_csv(\"c2013.csv\", index=False)\n",
    "#c2014.to_csv(\"c2014.csv\", index=False)\n",
    "#c2015.to_csv(\"c2015.csv\", index=False)\n",
    "#c2016.to_csv(\"c2016.csv\", index=False)\n",
    "#c2017.to_csv(\"c2017.csv\", index=False)\n",
    "#c2018.to_csv(\"c2018.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
